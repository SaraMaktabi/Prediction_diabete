{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ“Š CHARGEMENT DES RÃ‰SULTATS DE TOUS LES DATASETS\n",
      "================================================================================\n",
      "\n",
      "âœ… Total: 23 modÃ¨les entraÃ®nÃ©s\n",
      "   - Symptoms: 7 modÃ¨les\n",
      "   - Clinical: 8 modÃ¨les\n",
      "   - Pima: 8 modÃ¨les\n",
      "\n",
      "================================================================================\n",
      "ğŸ† MEILLEURS MODÃˆLES PAR DATASET (selon F1-Score)\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Symptoms (600):\n",
      "   ğŸ¥‡ ModÃ¨le: Random Forest\n",
      "   Accuracy:  0.8947\n",
      "   Precision: 0.9231\n",
      "   Recall:    0.9231\n",
      "   F1-Score:  0.9231\n",
      "   ROC-AUC:   0.9615\n",
      "\n",
      "ğŸ“ Clinical (10000):\n",
      "   ğŸ¥‡ ModÃ¨le: XGBoost\n",
      "   Accuracy:  1.0000\n",
      "   Precision: 1.0000\n",
      "   Recall:    1.0000\n",
      "   F1-Score:  1.0000\n",
      "   ROC-AUC:   1.0000\n",
      "\n",
      "ğŸ“ Pima (768):\n",
      "   ğŸ¥‡ ModÃ¨le: Gradient Boosting\n",
      "   Accuracy:  0.7739\n",
      "   Precision: 0.6667\n",
      "   Recall:    0.7000\n",
      "   F1-Score:  0.6829\n",
      "   ROC-AUC:   0.8367\n",
      "\n",
      "================================================================================\n",
      "ğŸ† CHAMPION ABSOLU (sur Validation Set)\n",
      "================================================================================\n",
      "\n",
      "ğŸ¥‡ ModÃ¨le: XGBoost\n",
      "ğŸ“ Dataset: Clinical (10000)\n",
      "ğŸ“Š MÃ©triques:\n",
      "   Accuracy:  1.0000\n",
      "   Precision: 1.0000\n",
      "   Recall:    1.0000\n",
      "   F1-Score:  1.0000\n",
      "   ROC-AUC:   1.0000\n",
      "\n",
      "âš ï¸  ATTENTION: 100% sur validation peut indiquer de l'overfitting!\n",
      "   â†’ On va TESTER sur le TEST SET pour vÃ©rifier...\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ˆ CRÃ‰ATION DES VISUALISATIONS COMPARATIVES\n",
      "================================================================================\n",
      "âœ… SauvegardÃ©: heatmap_all_datasets.png\n",
      "âœ… SauvegardÃ©: comparison_by_dataset_final.png\n",
      "\n",
      "ğŸ“Š RÃ©sumÃ© - Meilleure Performance par Dataset:\n",
      "                  Accuracy  Precision  Recall  F1-Score  ROC-AUC\n",
      "Dataset                                                         \n",
      "Clinical (10000)    1.0000     1.0000  1.0000    1.0000   1.0000\n",
      "Pima (768)          0.7739     0.6765  0.7250    0.6829   0.8367\n",
      "Symptoms (600)      0.8947     1.0000  0.9231    0.9231   0.9615\n",
      "\n",
      "================================================================================\n",
      "ğŸ”¬ Ã‰VALUATION SUR TEST SET - DÃ‰TECTION OVERFITTING\n",
      "================================================================================\n",
      "âš ï¸  Le test set n'a JAMAIS Ã©tÃ© vu par les modÃ¨les!\n",
      "   â†’ Performance rÃ©elle et honnÃªte\n",
      "\n",
      "\n",
      "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
      "TEST 1: CLINICAL DATASET - XGBoost (100% sur validation)\n",
      "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ Dataset: Clinical (10000)\n",
      "================================================================================\n",
      "âœ… ModÃ¨le chargÃ©: xgboost.pkl\n",
      "ğŸ“Š Test set: 1002 samples\n",
      "   DiabÃ©tiques: 400 (39.9%)\n",
      "\n",
      "ğŸ¯ RÃ‰SULTATS TEST SET:\n",
      "   Accuracy: 1.0000\n",
      "   Precision: 1.0000\n",
      "   Recall: 1.0000\n",
      "   F1-Score: 1.0000\n",
      "   ROC-AUC: 1.0000\n",
      "\n",
      "ğŸ“Š Matrice de Confusion:\n",
      "[[602   0]\n",
      " [  0 400]]\n",
      "\n",
      "   True Negatives:  602\n",
      "   False Positives: 0\n",
      "   False Negatives: 0\n",
      "   True Positives:  400\n",
      "\n",
      "ğŸ“‹ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       602\n",
      "           1       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           1.00      1002\n",
      "   macro avg       1.00      1.00      1.00      1002\n",
      "weighted avg       1.00      1.00      1.00      1002\n",
      "\n",
      "\n",
      "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
      "TEST 2: SYMPTOMS DATASET - Random Forest (96.2% sur validation)\n",
      "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ Dataset: Symptoms (600)\n",
      "================================================================================\n",
      "âœ… ModÃ¨le chargÃ©: random_forest.pkl\n",
      "ğŸ“Š Test set: 38 samples\n",
      "   DiabÃ©tiques: 26 (68.4%)\n",
      "\n",
      "ğŸ¯ RÃ‰SULTATS TEST SET:\n",
      "   Accuracy: 0.9211\n",
      "   Precision: 0.9600\n",
      "   Recall: 0.9231\n",
      "   F1-Score: 0.9412\n",
      "   ROC-AUC: 0.9615\n",
      "\n",
      "ğŸ“Š Matrice de Confusion:\n",
      "[[11  1]\n",
      " [ 2 24]]\n",
      "\n",
      "   True Negatives:  11\n",
      "   False Positives: 1\n",
      "   False Negatives: 2\n",
      "   True Positives:  24\n",
      "\n",
      "ğŸ“‹ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88        12\n",
      "           1       0.96      0.92      0.94        26\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.90      0.92      0.91        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "\n",
      "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
      "TEST 3: PIMA DATASET - Gradient Boosting (68.3% sur validation)\n",
      "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ Dataset: Pima (768)\n",
      "================================================================================\n",
      "âœ… ModÃ¨le chargÃ©: gradient_boosting.pkl\n",
      "ğŸ“Š Test set: 116 samples\n",
      "   DiabÃ©tiques: 41 (35.3%)\n",
      "\n",
      "ğŸ¯ RÃ‰SULTATS TEST SET:\n",
      "   Accuracy: 0.7414\n",
      "   Precision: 0.6897\n",
      "   Recall: 0.4878\n",
      "   F1-Score: 0.5714\n",
      "   ROC-AUC: 0.8101\n",
      "\n",
      "ğŸ“Š Matrice de Confusion:\n",
      "[[66  9]\n",
      " [21 20]]\n",
      "\n",
      "   True Negatives:  66\n",
      "   False Positives: 9\n",
      "   False Negatives: 21\n",
      "   True Positives:  20\n",
      "\n",
      "ğŸ“‹ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.81        75\n",
      "           1       0.69      0.49      0.57        41\n",
      "\n",
      "    accuracy                           0.74       116\n",
      "   macro avg       0.72      0.68      0.69       116\n",
      "weighted avg       0.73      0.74      0.73       116\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š COMPARAISON: VALIDATION SET vs TEST SET\n",
      "================================================================================\n",
      "\n",
      " Dataset             Model  Val_Accuracy  Test_Accuracy   Val_F1  Test_F1  Accuracy_Drop   F1_Drop\n",
      "Clinical           XGBoost      1.000000       1.000000 1.000000 1.000000       0.000000  0.000000\n",
      "Symptoms     Random Forest      0.894737       0.921053 0.923077 0.941176      -0.026316 -0.018100\n",
      "    Pima Gradient Boosting      0.773913       0.741379 0.682927 0.571429       0.032534  0.111498\n",
      "\n",
      "âœ… SauvegardÃ©: validation_vs_test_comparison.csv\n",
      "\n",
      "================================================================================\n",
      "ğŸ”¬ ANALYSE OVERFITTING\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Clinical:\n",
      "   Accuracy drop: 0.00%\n",
      "   F1-Score drop: 0.00%\n",
      "   âœ… Excellent! Pas d'overfitting significatif\n",
      "\n",
      "ğŸ“ Symptoms:\n",
      "   Accuracy drop: -2.63%\n",
      "   F1-Score drop: -1.81%\n",
      "   âœ… Excellent! Pas d'overfitting significatif\n",
      "\n",
      "ğŸ“ Pima:\n",
      "   Accuracy drop: 3.25%\n",
      "   F1-Score drop: 11.15%\n",
      "   âŒ OVERFITTING SÃ‰VÃˆRE!\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š CRÃ‰ATION MATRICES DE CONFUSION\n",
      "================================================================================\n",
      "âœ… SauvegardÃ©: confusion_matrices_test.png\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ˆ CRÃ‰ATION COURBES ROC\n",
      "================================================================================\n",
      "âœ… SauvegardÃ©: roc_curves_test.png\n",
      "\n",
      "================================================================================\n",
      "ğŸ† VERDICT FINAL\n",
      "================================================================================\n",
      "\n",
      "ğŸ¥‡ CHAMPION ABSOLU (Test Set): Clinical Dataset - XGBoost\n",
      "\n",
      "ğŸ“Š Performance sur donnÃ©es JAMAIS VUES:\n",
      "   Accuracy:  1.0000 (100.00%)\n",
      "   Precision: 1.0000 (100.00%)\n",
      "   Recall:    1.0000 (100.00%)\n",
      "   F1-Score:  1.0000 (100.00%)\n",
      "   ROC-AUC:   1.0000 (100.00%)\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¡ RECOMMANDATIONS\n",
      "================================================================================\n",
      "\n",
      "âœ… Le modÃ¨le Clinical-XGBoost est EXCELLENT!\n",
      "   - Performance exceptionnelle sur donnÃ©es mÃ©dicales\n",
      "   - PrÃªt pour utilisation clinique (avec validation supplÃ©mentaire)\n",
      "   - Dataset de 10,000 patients permet gÃ©nÃ©ralisation robuste\n",
      "\n",
      "ğŸ¯ MODÃˆLE RECOMMANDÃ‰ POUR PRODUCTION:\n",
      "   â†’ Clinical Dataset - XGBoost\n",
      "   â†’ F1-Score Test: 1.0000\n",
      "\n",
      "================================================================================\n",
      "âœ… ANALYSE COMPLÃˆTE TERMINÃ‰E!\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Fichiers gÃ©nÃ©rÃ©s:\n",
      "   - heatmap_all_datasets.png\n",
      "   - comparison_by_dataset_final.png\n",
      "   - confusion_matrices_test.png\n",
      "   - roc_curves_test.png\n",
      "   - validation_vs_test_comparison.csv\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 5: COMPARAISON FINALE + Ã‰VALUATION TEST SET\n",
    "====================================================\n",
    "Ce notebook va:\n",
    "1. Comparer tous les rÃ©sultats des 3 datasets\n",
    "2. Identifier le champion\n",
    "3. TESTER sur le TEST SET pour vÃ©rifier l'overfitting\n",
    "4. Donner le verdict final\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 1: CHARGER TOUS LES RÃ‰SULTATS\n",
    "# ============================================\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š CHARGEMENT DES RÃ‰SULTATS DE TOUS LES DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Charger les 3 fichiers de rÃ©sultats\n",
    "results_symptoms = pd.read_csv('../results/metrics/symptoms_models_comparison.csv')\n",
    "results_clinical = pd.read_csv('../results/metrics/clinical_models_comparison.csv')\n",
    "results_pima = pd.read_csv('../results/metrics/pima_models_comparison.csv')\n",
    "\n",
    "# Ajouter colonne dataset\n",
    "results_symptoms['Dataset'] = 'Symptoms (600)'\n",
    "results_clinical['Dataset'] = 'Clinical (10000)'\n",
    "results_pima['Dataset'] = 'Pima (768)'\n",
    "\n",
    "# Combiner tous les rÃ©sultats\n",
    "all_results = pd.concat([results_symptoms, results_clinical, results_pima], ignore_index=True)\n",
    "\n",
    "print(f\"\\nâœ… Total: {len(all_results)} modÃ¨les entraÃ®nÃ©s\")\n",
    "print(f\"   - Symptoms: {len(results_symptoms)} modÃ¨les\")\n",
    "print(f\"   - Clinical: {len(results_clinical)} modÃ¨les\")\n",
    "print(f\"   - Pima: {len(results_pima)} modÃ¨les\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 2: TOP MODÃˆLES PAR DATASET\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ† MEILLEURS MODÃˆLES PAR DATASET (selon F1-Score)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for dataset_name in ['Symptoms (600)', 'Clinical (10000)', 'Pima (768)']:\n",
    "    subset = all_results[all_results['Dataset'] == dataset_name].sort_values('F1-Score', ascending=False)\n",
    "    best = subset.iloc[0]\n",
    "    \n",
    "    print(f\"\\nğŸ“ {dataset_name}:\")\n",
    "    print(f\"   ğŸ¥‡ ModÃ¨le: {best['Model']}\")\n",
    "    print(f\"   Accuracy:  {best['Accuracy']:.4f}\")\n",
    "    print(f\"   Precision: {best['Precision']:.4f}\")\n",
    "    print(f\"   Recall:    {best['Recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {best['F1-Score']:.4f}\")\n",
    "    print(f\"   ROC-AUC:   {best['ROC-AUC']:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 3: CHAMPION ABSOLU (VALIDATION SET)\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ† CHAMPION ABSOLU (sur Validation Set)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_overall = all_results.sort_values('F1-Score', ascending=False).iloc[0]\n",
    "print(f\"\\nğŸ¥‡ ModÃ¨le: {best_overall['Model']}\")\n",
    "print(f\"ğŸ“ Dataset: {best_overall['Dataset']}\")\n",
    "print(f\"ğŸ“Š MÃ©triques:\")\n",
    "print(f\"   Accuracy:  {best_overall['Accuracy']:.4f}\")\n",
    "print(f\"   Precision: {best_overall['Precision']:.4f}\")\n",
    "print(f\"   Recall:    {best_overall['Recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {best_overall['F1-Score']:.4f}\")\n",
    "print(f\"   ROC-AUC:   {best_overall['ROC-AUC']:.4f}\")\n",
    "\n",
    "print(\"\\nâš ï¸  ATTENTION: 100% sur validation peut indiquer de l'overfitting!\")\n",
    "print(\"   â†’ On va TESTER sur le TEST SET pour vÃ©rifier...\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 4: VISUALISATION COMPARATIVE\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“ˆ CRÃ‰ATION DES VISUALISATIONS COMPARATIVES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Heatmap F1-Score\n",
    "pivot = all_results.pivot_table(\n",
    "    values='F1-Score', \n",
    "    index='Model', \n",
    "    columns='Dataset'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(pivot, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "            vmin=0.5, vmax=1.0, cbar_kws={'label': 'F1-Score'})\n",
    "plt.title('Heatmap F1-Score: Tous ModÃ¨les sur Tous Datasets', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Dataset', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('ModÃ¨le', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/visualizations/heatmap_all_datasets.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ… SauvegardÃ©: heatmap_all_datasets.png\")\n",
    "plt.close()\n",
    "\n",
    "# Graphique comparatif par dataset\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "for idx, dataset_name in enumerate(['Symptoms (600)', 'Clinical (10000)', 'Pima (768)']):\n",
    "    subset = all_results[all_results['Dataset'] == dataset_name].sort_values('F1-Score', ascending=False)\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    bars = ax.barh(subset['Model'], subset['F1-Score'], \n",
    "                   color=['#2ecc71' if i == 0 else '#3498db' for i in range(len(subset))])\n",
    "    ax.set_xlabel('F1-Score', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(dataset_name, fontsize=13, fontweight='bold')\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Ajouter valeurs\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.3f}', \n",
    "                ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Comparaison F1-Score par Dataset', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/visualizations/comparison_by_dataset_final.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ… SauvegardÃ©: comparison_by_dataset_final.png\")\n",
    "plt.close()\n",
    "\n",
    "# Tableau rÃ©capitulatif\n",
    "summary = all_results.groupby('Dataset').agg({\n",
    "    'Accuracy': 'max',\n",
    "    'Precision': 'max',\n",
    "    'Recall': 'max',\n",
    "    'F1-Score': 'max',\n",
    "    'ROC-AUC': 'max'\n",
    "}).round(4)\n",
    "\n",
    "print(\"\\nğŸ“Š RÃ©sumÃ© - Meilleure Performance par Dataset:\")\n",
    "print(summary)\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 5: TEST SUR LE TEST SET - VÃ‰RIFICATION OVERFITTING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ”¬ Ã‰VALUATION SUR TEST SET - DÃ‰TECTION OVERFITTING\")\n",
    "print(\"=\"*80)\n",
    "print(\"âš ï¸  Le test set n'a JAMAIS Ã©tÃ© vu par les modÃ¨les!\")\n",
    "print(\"   â†’ Performance rÃ©elle et honnÃªte\\n\")\n",
    "\n",
    "def evaluate_on_test_set(model_path, dataset_path, target_col, dataset_name):\n",
    "    \"\"\"Ã‰value un modÃ¨le sur le test set\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ“ Dataset: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Charger le modÃ¨le\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"âœ… ModÃ¨le chargÃ©: {model_path.split('/')[-1]}\")\n",
    "    \n",
    "    # Charger les donnÃ©es\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # MÃªme split que l'entraÃ®nement (random_state=42)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "    \n",
    "    print(f\"ğŸ“Š Test set: {len(X_test)} samples\")\n",
    "    print(f\"   DiabÃ©tiques: {y_test.sum()} ({y_test.sum()/len(y_test)*100:.1f}%)\")\n",
    "    \n",
    "    # PrÃ©dictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # MÃ©triques\n",
    "    test_metrics = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "        'F1-Score': f1_score(y_test, y_pred, zero_division=0),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸ¯ RÃ‰SULTATS TEST SET:\")\n",
    "    for metric, value in test_metrics.items():\n",
    "        if value is not None:\n",
    "            print(f\"   {metric}: {value:.4f}\")\n",
    "    \n",
    "    # Matrice de confusion\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\nğŸ“Š Matrice de Confusion:\")\n",
    "    print(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"\\n   True Negatives:  {tn}\")\n",
    "    print(f\"   False Positives: {fp}\")\n",
    "    print(f\"   False Negatives: {fn}\")\n",
    "    print(f\"   True Positives:  {tp}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"\\nğŸ“‹ Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    \n",
    "    return test_metrics, y_test, y_pred, y_proba, cm\n",
    "\n",
    "# ============================================\n",
    "# TEST 1: CLINICAL DATASET (XGBoost - 100% sur validation)\n",
    "# ============================================\n",
    "print(\"\\n\" + \"ğŸ”\"*40)\n",
    "print(\"TEST 1: CLINICAL DATASET - XGBoost (100% sur validation)\")\n",
    "print(\"ğŸ”\"*40)\n",
    "\n",
    "clinical_metrics, clinical_y_test, clinical_y_pred, clinical_y_proba, clinical_cm = evaluate_on_test_set(\n",
    "    model_path='../models/clinical/xgboost.pkl',\n",
    "    dataset_path='../data/Dataset_10000_Lignes/dataset_clinical_ready.csv',\n",
    "    target_col='Diabetes',\n",
    "    dataset_name='Clinical (10000)'\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# TEST 2: SYMPTOMS DATASET (Random Forest - 96.2%)\n",
    "# ============================================\n",
    "print(\"\\n\" + \"ğŸ”\"*40)\n",
    "print(\"TEST 2: SYMPTOMS DATASET - Random Forest (96.2% sur validation)\")\n",
    "print(\"ğŸ”\"*40)\n",
    "\n",
    "symptoms_metrics, symptoms_y_test, symptoms_y_pred, symptoms_y_proba, symptoms_cm = evaluate_on_test_set(\n",
    "    model_path='../models/symptoms/random_forest.pkl',\n",
    "    dataset_path='../data/Dataset_600_Lignes/dataset_ready_for_ml.csv',\n",
    "    target_col='class',\n",
    "    dataset_name='Symptoms (600)'\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# TEST 3: PIMA DATASET (Gradient Boosting - 68.3%)\n",
    "# ============================================\n",
    "print(\"\\n\" + \"ğŸ”\"*40)\n",
    "print(\"TEST 3: PIMA DATASET - Gradient Boosting (68.3% sur validation)\")\n",
    "print(\"ğŸ”\"*40)\n",
    "\n",
    "pima_metrics, pima_y_test, pima_y_pred, pima_y_proba, pima_cm = evaluate_on_test_set(\n",
    "    model_path='../models/pima/gradient_boosting.pkl',\n",
    "    dataset_path='../data/Dataset_Pregnancies/pima_ready_for_ml.csv',\n",
    "    target_col='Outcome',\n",
    "    dataset_name='Pima (768)'\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 6: COMPARAISON VALIDATION vs TEST\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š COMPARAISON: VALIDATION SET vs TEST SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Dataset': ['Clinical', 'Symptoms', 'Pima'],\n",
    "    'Model': ['XGBoost', 'Random Forest', 'Gradient Boosting'],\n",
    "    'Val_Accuracy': [\n",
    "        results_clinical[results_clinical['Model'] == 'XGBoost']['Accuracy'].values[0],\n",
    "        results_symptoms[results_symptoms['Model'] == 'Random Forest']['Accuracy'].values[0],\n",
    "        results_pima[results_pima['Model'] == 'Gradient Boosting']['Accuracy'].values[0]\n",
    "    ],\n",
    "    'Test_Accuracy': [\n",
    "        clinical_metrics['Accuracy'],\n",
    "        symptoms_metrics['Accuracy'],\n",
    "        pima_metrics['Accuracy']\n",
    "    ],\n",
    "    'Val_F1': [\n",
    "        results_clinical[results_clinical['Model'] == 'XGBoost']['F1-Score'].values[0],\n",
    "        results_symptoms[results_symptoms['Model'] == 'Random Forest']['F1-Score'].values[0],\n",
    "        results_pima[results_pima['Model'] == 'Gradient Boosting']['F1-Score'].values[0]\n",
    "    ],\n",
    "    'Test_F1': [\n",
    "        clinical_metrics['F1-Score'],\n",
    "        symptoms_metrics['F1-Score'],\n",
    "        pima_metrics['F1-Score']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Calculer la diffÃ©rence (drop = overfitting)\n",
    "comparison_df['Accuracy_Drop'] = comparison_df['Val_Accuracy'] - comparison_df['Test_Accuracy']\n",
    "comparison_df['F1_Drop'] = comparison_df['Val_F1'] - comparison_df['Test_F1']\n",
    "\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# Sauvegarder\n",
    "comparison_df.to_csv('../results/metrics/validation_vs_test_comparison.csv', index=False)\n",
    "print(\"\\nâœ… SauvegardÃ©: validation_vs_test_comparison.csv\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 7: ANALYSE OVERFITTING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ”¬ ANALYSE OVERFITTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    dataset = row['Dataset']\n",
    "    acc_drop = row['Accuracy_Drop'] * 100\n",
    "    f1_drop = row['F1_Drop'] * 100\n",
    "    \n",
    "    print(f\"\\nğŸ“ {dataset}:\")\n",
    "    print(f\"   Accuracy drop: {acc_drop:.2f}%\")\n",
    "    print(f\"   F1-Score drop: {f1_drop:.2f}%\")\n",
    "    \n",
    "    if acc_drop < 1 and f1_drop < 1:\n",
    "        print(f\"   âœ… Excellent! Pas d'overfitting significatif\")\n",
    "    elif acc_drop < 5 and f1_drop < 5:\n",
    "        print(f\"   âš ï¸  LÃ©ger overfitting (acceptable)\")\n",
    "    elif acc_drop < 10 and f1_drop < 10:\n",
    "        print(f\"   âš ï¸  Overfitting modÃ©rÃ©\")\n",
    "    else:\n",
    "        print(f\"   âŒ OVERFITTING SÃ‰VÃˆRE!\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 8: VISUALISATION MATRICES DE CONFUSION\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š CRÃ‰ATION MATRICES DE CONFUSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "datasets_info = [\n",
    "    ('Clinical', clinical_cm, 'XGBoost'),\n",
    "    ('Symptoms', symptoms_cm, 'Random Forest'),\n",
    "    ('Pima', pima_cm, 'Gradient Boosting')\n",
    "]\n",
    "\n",
    "for idx, (dataset_name, cm, model_name) in enumerate(datasets_info):\n",
    "    ax = axes[idx]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Non-DiabÃ©tique', 'DiabÃ©tique'],\n",
    "                yticklabels=['Non-DiabÃ©tique', 'DiabÃ©tique'],\n",
    "                cbar=False)\n",
    "    ax.set_title(f'{dataset_name}\\n{model_name}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Vraie Classe', fontsize=10)\n",
    "    ax.set_xlabel('Classe PrÃ©dite', fontsize=10)\n",
    "\n",
    "plt.suptitle('Matrices de Confusion - Test Set', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/visualizations/confusion_matrices_test.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ… SauvegardÃ©: confusion_matrices_test.png\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 9: COURBES ROC\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“ˆ CRÃ‰ATION COURBES ROC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Clinical\n",
    "fpr_c, tpr_c, _ = roc_curve(clinical_y_test, clinical_y_proba)\n",
    "roc_auc_c = auc(fpr_c, tpr_c)\n",
    "plt.plot(fpr_c, tpr_c, label=f'Clinical - XGBoost (AUC = {roc_auc_c:.3f})', linewidth=2)\n",
    "\n",
    "# Symptoms\n",
    "fpr_s, tpr_s, _ = roc_curve(symptoms_y_test, symptoms_y_proba)\n",
    "roc_auc_s = auc(fpr_s, tpr_s)\n",
    "plt.plot(fpr_s, tpr_s, label=f'Symptoms - Random Forest (AUC = {roc_auc_s:.3f})', linewidth=2)\n",
    "\n",
    "# Pima\n",
    "fpr_p, tpr_p, _ = roc_curve(pima_y_test, pima_y_proba)\n",
    "roc_auc_p = auc(fpr_p, tpr_p)\n",
    "plt.plot(fpr_p, tpr_p, label=f'Pima - Gradient Boosting (AUC = {roc_auc_p:.3f})', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.5)', linewidth=1)\n",
    "plt.xlabel('Taux de Faux Positifs', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Taux de Vrais Positifs', fontsize=12, fontweight='bold')\n",
    "plt.title('Courbes ROC - Test Set (Meilleurs ModÃ¨les)', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/visualizations/roc_curves_test.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ… SauvegardÃ©: roc_curves_test.png\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 10: VERDICT FINAL\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ† VERDICT FINAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Trouver le meilleur sur test set\n",
    "best_test_f1 = max(clinical_metrics['F1-Score'], \n",
    "                   symptoms_metrics['F1-Score'], \n",
    "                   pima_metrics['F1-Score'])\n",
    "\n",
    "if best_test_f1 == clinical_metrics['F1-Score']:\n",
    "    winner = \"Clinical Dataset - XGBoost\"\n",
    "    winner_metrics = clinical_metrics\n",
    "elif best_test_f1 == symptoms_metrics['F1-Score']:\n",
    "    winner = \"Symptoms Dataset - Random Forest\"\n",
    "    winner_metrics = symptoms_metrics\n",
    "else:\n",
    "    winner = \"Pima Dataset - Gradient Boosting\"\n",
    "    winner_metrics = pima_metrics\n",
    "\n",
    "print(f\"\\nğŸ¥‡ CHAMPION ABSOLU (Test Set): {winner}\")\n",
    "print(f\"\\nğŸ“Š Performance sur donnÃ©es JAMAIS VUES:\")\n",
    "print(f\"   Accuracy:  {winner_metrics['Accuracy']:.4f} ({winner_metrics['Accuracy']*100:.2f}%)\")\n",
    "print(f\"   Precision: {winner_metrics['Precision']:.4f} ({winner_metrics['Precision']*100:.2f}%)\")\n",
    "print(f\"   Recall:    {winner_metrics['Recall']:.4f} ({winner_metrics['Recall']*100:.2f}%)\")\n",
    "print(f\"   F1-Score:  {winner_metrics['F1-Score']:.4f} ({winner_metrics['F1-Score']*100:.2f}%)\")\n",
    "print(f\"   ROC-AUC:   {winner_metrics['ROC-AUC']:.4f} ({winner_metrics['ROC-AUC']*100:.2f}%)\")\n",
    "\n",
    "# Recommandations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ’¡ RECOMMANDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if clinical_metrics['Accuracy'] > 0.95:\n",
    "    print(\"\\nâœ… Le modÃ¨le Clinical-XGBoost est EXCELLENT!\")\n",
    "    print(\"   - Performance exceptionnelle sur donnÃ©es mÃ©dicales\")\n",
    "    print(\"   - PrÃªt pour utilisation clinique (avec validation supplÃ©mentaire)\")\n",
    "    print(\"   - Dataset de 10,000 patients permet gÃ©nÃ©ralisation robuste\")\n",
    "\n",
    "if comparison_df['Accuracy_Drop'].max() > 0.1:\n",
    "    print(\"\\nâš ï¸  Attention: Certains modÃ¨les montrent de l'overfitting\")\n",
    "    print(\"   Solutions:\")\n",
    "    print(\"   - Augmenter regularisation\")\n",
    "    print(\"   - RÃ©duire complexitÃ© du modÃ¨le\")\n",
    "    print(\"   - Collecter plus de donnÃ©es\")\n",
    "\n",
    "print(\"\\nğŸ¯ MODÃˆLE RECOMMANDÃ‰ POUR PRODUCTION:\")\n",
    "print(f\"   â†’ {winner}\")\n",
    "print(f\"   â†’ F1-Score Test: {winner_metrics['F1-Score']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ANALYSE COMPLÃˆTE TERMINÃ‰E!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nğŸ“ Fichiers gÃ©nÃ©rÃ©s:\")\n",
    "print(\"   - heatmap_all_datasets.png\")\n",
    "print(\"   - comparison_by_dataset_final.png\")\n",
    "print(\"   - confusion_matrices_test.png\")\n",
    "print(\"   - roc_curves_test.png\")\n",
    "print(\"   - validation_vs_test_comparison.csv\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
